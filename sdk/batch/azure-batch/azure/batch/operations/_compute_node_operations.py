# pylint: disable=too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import datetime
import sys
from typing import Any, Callable, Dict, IO, Iterable, Optional, TypeVar, cast

from msrest import Serializer

from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
from azure.core.paging import ItemPaged
from azure.core.pipeline import PipelineResponse
from azure.core.pipeline.transport import HttpResponse
from azure.core.rest import HttpRequest
from azure.core.tracing.decorator import distributed_trace
from azure.core.utils import case_insensitive_dict

from .._vendor import _format_url_section
if sys.version_info >= (3, 9):
    from collections.abc import MutableMapping
else:
    from typing import MutableMapping  # type: ignore
JSON = MutableMapping[str, Any] # pylint: disable=unsubscriptable-object
T = TypeVar('T')
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]

_SERIALIZER = Serializer()
_SERIALIZER.client_side_validation = False

def build_add_user_request(
    pool_id: str,
    node_id: str,
    *,
    json: Optional[JSON] = None,
    content: Any = None,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    content_type = kwargs.pop('content_type', _headers.pop('Content-Type', None))  # type: Optional[str]
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}/users"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    if content_type is not None:
        _headers['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="POST",
        url=_url,
        params=_params,
        headers=_headers,
        json=json,
        content=content,
        **kwargs
    )


def build_delete_user_request(
    pool_id: str,
    node_id: str,
    user_name: str,
    *,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}/users/{userName}"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
        "userName": _SERIALIZER.url("user_name", user_name, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="DELETE",
        url=_url,
        params=_params,
        headers=_headers,
        **kwargs
    )


def build_update_user_request(
    pool_id: str,
    node_id: str,
    user_name: str,
    *,
    json: Optional[JSON] = None,
    content: Any = None,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    content_type = kwargs.pop('content_type', _headers.pop('Content-Type', None))  # type: Optional[str]
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}/users/{userName}"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
        "userName": _SERIALIZER.url("user_name", user_name, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    if content_type is not None:
        _headers['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="PUT",
        url=_url,
        params=_params,
        headers=_headers,
        json=json,
        content=content,
        **kwargs
    )


def build_get_request(
    pool_id: str,
    node_id: str,
    *,
    select: Optional[str] = None,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if select is not None:
        _params['$select'] = _SERIALIZER.query("select", select, 'str')
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="GET",
        url=_url,
        params=_params,
        headers=_headers,
        **kwargs
    )


def build_reboot_request(
    pool_id: str,
    node_id: str,
    *,
    json: Optional[JSON] = None,
    content: Any = None,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    content_type = kwargs.pop('content_type', _headers.pop('Content-Type', None))  # type: Optional[str]
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}/reboot"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    if content_type is not None:
        _headers['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="POST",
        url=_url,
        params=_params,
        headers=_headers,
        json=json,
        content=content,
        **kwargs
    )


def build_reimage_request(
    pool_id: str,
    node_id: str,
    *,
    json: Optional[JSON] = None,
    content: Any = None,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    content_type = kwargs.pop('content_type', _headers.pop('Content-Type', None))  # type: Optional[str]
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}/reimage"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    if content_type is not None:
        _headers['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="POST",
        url=_url,
        params=_params,
        headers=_headers,
        json=json,
        content=content,
        **kwargs
    )


def build_disable_scheduling_request(
    pool_id: str,
    node_id: str,
    *,
    json: Optional[JSON] = None,
    content: Any = None,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    content_type = kwargs.pop('content_type', _headers.pop('Content-Type', None))  # type: Optional[str]
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}/disablescheduling"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    if content_type is not None:
        _headers['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="POST",
        url=_url,
        params=_params,
        headers=_headers,
        json=json,
        content=content,
        **kwargs
    )


def build_enable_scheduling_request(
    pool_id: str,
    node_id: str,
    *,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}/enablescheduling"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="POST",
        url=_url,
        params=_params,
        headers=_headers,
        **kwargs
    )


def build_get_remote_login_settings_request(
    pool_id: str,
    node_id: str,
    *,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}/remoteloginsettings"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="GET",
        url=_url,
        params=_params,
        headers=_headers,
        **kwargs
    )


def build_get_remote_desktop_request(
    pool_id: str,
    node_id: str,
    *,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    accept = _headers.pop('Accept', "application/json, application/octet-stream")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}/rdp"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="GET",
        url=_url,
        params=_params,
        headers=_headers,
        **kwargs
    )


def build_upload_batch_service_logs_request(
    pool_id: str,
    node_id: str,
    *,
    json: Optional[JSON] = None,
    content: Any = None,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    content_type = kwargs.pop('content_type', _headers.pop('Content-Type', None))  # type: Optional[str]
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes/{nodeId}/uploadbatchservicelogs"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
        "nodeId": _SERIALIZER.url("node_id", node_id, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    if content_type is not None:
        _headers['Content-Type'] = _SERIALIZER.header("content_type", content_type, 'str')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="POST",
        url=_url,
        params=_params,
        headers=_headers,
        json=json,
        content=content,
        **kwargs
    )


def build_list_request(
    pool_id: str,
    *,
    filter: Optional[str] = None,
    select: Optional[str] = None,
    max_results: Optional[int] = 1000,
    timeout: Optional[int] = 30,
    client_request_id: Optional[str] = None,
    return_client_request_id: Optional[bool] = False,
    ocp_date: Optional[datetime.datetime] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
    accept = _headers.pop('Accept', "application/json")

    # Construct URL
    _url = "/pools/{poolId}/nodes"
    path_format_arguments = {
        "poolId": _SERIALIZER.url("pool_id", pool_id, 'str'),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct parameters
    if filter is not None:
        _params['$filter'] = _SERIALIZER.query("filter", filter, 'str')
    if select is not None:
        _params['$select'] = _SERIALIZER.query("select", select, 'str')
    if max_results is not None:
        _params['maxresults'] = _SERIALIZER.query("max_results", max_results, 'int', maximum=1000, minimum=1)
    if timeout is not None:
        _params['timeout'] = _SERIALIZER.query("timeout", timeout, 'int')
    _params['api-version'] = _SERIALIZER.query("api_version", api_version, 'str')

    # Construct headers
    if client_request_id is not None:
        _headers['client-request-id'] = _SERIALIZER.header("client_request_id", client_request_id, 'str')
    if return_client_request_id is not None:
        _headers['return-client-request-id'] = _SERIALIZER.header("return_client_request_id", return_client_request_id, 'bool')
    if ocp_date is not None:
        _headers['ocp-date'] = _SERIALIZER.header("ocp_date", ocp_date, 'rfc-1123')
    _headers['Accept'] = _SERIALIZER.header("accept", accept, 'str')

    return HttpRequest(
        method="GET",
        url=_url,
        params=_params,
        headers=_headers,
        **kwargs
    )

class ComputeNodeOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~azure-batch.BatchServiceClient`'s
        :attr:`compute_node` attribute.
    """

    def __init__(self, *args, **kwargs):
        input_args = list(args)
        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")


    @distributed_trace
    def add_user(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        user: JSON,
        *,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Adds a user Account to the specified Compute Node.

        You can add a user Account to a Compute Node only when it is in the idle or running state.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the machine on which you want to create a user Account.
        :type node_id: str
        :param user: The user Account to be created.
        :type user: JSON
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: None
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                user = {
                    "expiryTime": "2020-02-20 00:00:00",  # Optional. If omitted, the default is
                      1 day from the current time. For Linux Compute Nodes, the expiryTime has a
                      precision up to a day.
                    "isAdmin": bool,  # Optional. The default value is false.
                    "name": "str",  # Required. The user name of the Account.
                    "password": "str",  # Optional. The password is required for Windows Compute
                      Nodes (those created with 'cloudServiceConfiguration', or created with
                      'virtualMachineConfiguration' using a Windows Image reference). For Linux Compute
                      Nodes, the password can optionally be specified along with the sshPublicKey
                      property.
                    "sshPublicKey": "str"  # Optional. The public key should be compatible with
                      OpenSSH encoding and should be base 64 encoded. This property can be specified
                      only for Linux Compute Nodes. If this is specified for a Windows Compute Node,
                      then the Batch service rejects the request; if you are calling the REST API
                      directly, the HTTP status code is 400 (Bad Request).
                }
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        content_type = kwargs.pop('content_type', _headers.pop('Content-Type', "application/json; odata=minimalmetadata"))  # type: Optional[str]
        cls = kwargs.pop('cls', None)  # type: ClsType[None]

        _content = user

        request = build_add_user_request(
            pool_id=pool_id,
            node_id=node_id,
            api_version=api_version,
            content_type=content_type,
            content=_content,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))
        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
        response_headers['DataServiceId']=self._deserialize('str', response.headers.get('DataServiceId'))


        if cls:
            return cls(pipeline_response, None, response_headers)



    @distributed_trace
    def delete_user(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        user_name: str,
        *,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Deletes a user Account from the specified Compute Node.

        You can delete a user Account to a Compute Node only when it is in the idle or running state.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the machine on which you want to delete a user Account.
        :type node_id: str
        :param user_name: The name of the user Account to delete.
        :type user_name: str
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: None
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        cls = kwargs.pop('cls', None)  # type: ClsType[None]

        
        request = build_delete_user_request(
            pool_id=pool_id,
            node_id=node_id,
            user_name=user_name,
            api_version=api_version,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))


        if cls:
            return cls(pipeline_response, None, response_headers)



    @distributed_trace
    def update_user(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        user_name: str,
        node_update_user_parameter: JSON,
        *,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Updates the password and expiration time of a user Account on the specified Compute Node.

        This operation replaces of all the updatable properties of the Account. For example, if the
        expiryTime element is not specified, the current value is replaced with the default value, not
        left unmodified. You can update a user Account on a Compute Node only when it is in the idle or
        running state.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the machine on which you want to update a user Account.
        :type node_id: str
        :param user_name: The name of the user Account to update.
        :type user_name: str
        :param node_update_user_parameter: The parameters for the request.
        :type node_update_user_parameter: JSON
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: None
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                node_update_user_parameter = {
                    "expiryTime": "2020-02-20 00:00:00",  # Optional. If omitted, the default is
                      1 day from the current time. For Linux Compute Nodes, the expiryTime has a
                      precision up to a day.
                    "password": "str",  # Optional. The password is required for Windows Compute
                      Nodes (those created with 'cloudServiceConfiguration', or created with
                      'virtualMachineConfiguration' using a Windows Image reference). For Linux Compute
                      Nodes, the password can optionally be specified along with the sshPublicKey
                      property. If omitted, any existing password is removed.
                    "sshPublicKey": "str"  # Optional. The public key should be compatible with
                      OpenSSH encoding and should be base 64 encoded. This property can be specified
                      only for Linux Compute Nodes. If this is specified for a Windows Compute Node,
                      then the Batch service rejects the request; if you are calling the REST API
                      directly, the HTTP status code is 400 (Bad Request). If omitted, any existing SSH
                      public key is removed.
                }
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        content_type = kwargs.pop('content_type', _headers.pop('Content-Type', "application/json; odata=minimalmetadata"))  # type: Optional[str]
        cls = kwargs.pop('cls', None)  # type: ClsType[None]

        _content = node_update_user_parameter

        request = build_update_user_request(
            pool_id=pool_id,
            node_id=node_id,
            user_name=user_name,
            api_version=api_version,
            content_type=content_type,
            content=_content,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))
        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
        response_headers['DataServiceId']=self._deserialize('str', response.headers.get('DataServiceId'))


        if cls:
            return cls(pipeline_response, None, response_headers)



    @distributed_trace
    def get(
        self,
        pool_id: str,
        node_id: str,
        *,
        select: Optional[str] = None,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> JSON:
        """Gets information about the specified Compute Node.

        Gets information about the specified Compute Node.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the Compute Node that you want to get information about.
        :type node_id: str
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: str
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: JSON object
        :rtype: JSON
        :raises: ~azure.core.exceptions.HttpResponseError

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response.json() == {
                    "affinityId": "str",  # Optional. Note that this is just a soft affinity. If
                      the target Compute Node is busy or unavailable at the time the Task is scheduled,
                      then the Task will be scheduled elsewhere.
                    "allocationTime": "2020-02-20 00:00:00",  # Optional. This is the time when
                      the Compute Node was initially allocated and doesn't change once set. It is not
                      updated when the Compute Node is service healed or preempted.
                    "certificateReferences": [
                        {
                            "storeLocation": "str",  # Optional. The default value is
                              currentuser. This property is applicable only for Pools configured with
                              Windows Compute Nodes (that is, created with cloudServiceConfiguration,
                              or with virtualMachineConfiguration using a Windows Image reference). For
                              Linux Compute Nodes, the Certificates are stored in a directory inside
                              the Task working directory and an environment variable
                              AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
                              location. For Certificates with visibility of 'remoteUser', a 'certs'
                              directory is created in the user's home directory (e.g.,
                              /home/{user-name}/certs) and Certificates are placed in that directory.
                              Known values are: "currentuser", "localmachine".
                            "storeName": "str",  # Optional. This property is applicable
                              only for Pools configured with Windows Compute Nodes (that is, created
                              with cloudServiceConfiguration, or with virtualMachineConfiguration using
                              a Windows Image reference). Common store names include: My, Root, CA,
                              Trust, Disallowed, TrustedPeople, TrustedPublisher, AuthRoot,
                              AddressBook, but any custom store name can also be used. The default
                              value is My.
                            "thumbprint": "str",  # Required. The thumbprint of the
                              Certificate.
                            "thumbprintAlgorithm": "str",  # Required. The algorithm with
                              which the thumbprint is associated. This must be sha1.
                            "visibility": [
                                "str"  # Optional. You can specify more than one
                                  visibility in this collection. The default is all Accounts.
                            ]
                        }
                    ],
                    "endpointConfiguration": {
                        "inboundEndpoints": [
                            {
                                "backendPort": 0,  # Required. The backend port
                                  number of the endpoint.
                                "frontendPort": 0,  # Required. The public port
                                  number of the endpoint.
                                "name": "str",  # Required. The name of the endpoint.
                                "protocol": "str",  # Required. The protocol of the
                                  endpoint. Known values are: "tcp", "udp".
                                "publicFQDN": "str",  # Required. The public fully
                                  qualified domain name for the Compute Node.
                                "publicIPAddress": "str"  # Required. The public IP
                                  address of the Compute Node.
                            }
                        ]
                    },
                    "errors": [
                        {
                            "code": "str",  # Optional. An identifier for the Compute
                              Node error. Codes are invariant and are intended to be consumed
                              programmatically.
                            "errorDetails": [
                                {
                                    "name": "str",  # Optional. The name in the
                                      name-value pair.
                                    "value": "str"  # Optional. The value in the
                                      name-value pair.
                                }
                            ],
                            "message": "str"  # Optional. A message describing the
                              Compute Node error, intended to be suitable for display in a user
                              interface.
                        }
                    ],
                    "id": "str",  # Optional. Every Compute Node that is added to a Pool is
                      assigned a unique ID. Whenever a Compute Node is removed from a Pool, all of its
                      local files are deleted, and the ID is reclaimed and could be reused for new
                      Compute Nodes.
                    "ipAddress": "str",  # Optional. Every Compute Node that is added to a Pool
                      is assigned a unique IP address. Whenever a Compute Node is removed from a Pool,
                      all of its local files are deleted, and the IP address is reclaimed and could be
                      reused for new Compute Nodes.
                    "isDedicated": bool,  # Optional. Whether this Compute Node is a dedicated
                      Compute Node. If false, the Compute Node is a Spot/Low-priority Compute Node.
                    "lastBootTime": "2020-02-20 00:00:00",  # Optional. This property may not be
                      present if the Compute Node state is unusable.
                    "nodeAgentInfo": {
                        "lastUpdateTime": "2020-02-20 00:00:00",  # Required. This is the
                          most recent time that the Compute Node agent was updated to a new version.
                        "version": "str"  # Required. This version number can be checked
                          against the Compute Node agent release notes located at
                          https://github.com/Azure/Batch/blob/master/changelogs/nodeagent/CHANGELOG.md.
                    },
                    "recentTasks": [
                        {
                            "executionInfo": {
                                "containerInfo": {
                                    "containerId": "str",  # Optional. The ID of
                                      the container.
                                    "error": "str",  # Optional. This is the
                                      detailed error string from the Docker service, if available. It
                                      is equivalent to the error field returned by "docker inspect".
                                    "state": "str"  # Optional. This is the state
                                      of the container according to the Docker service. It is
                                      equivalent to the status field returned by "docker inspect".
                                },
                                "endTime": "2020-02-20 00:00:00",  # Optional. This
                                  property is set only if the Task is in the Completed state.
                                "exitCode": 0,  # Optional. This property is set only
                                  if the Task is in the completed state. In general, the exit code for
                                  a process reflects the specific convention implemented by the
                                  application developer for that process. If you use the exit code
                                  value to make decisions in your code, be sure that you know the exit
                                  code convention used by the application process. However, if the
                                  Batch service terminates the Task (due to timeout, or user
                                  termination via the API) you may see an operating system-defined exit
                                  code.
                                "failureInfo": {
                                    "category": "str",  # Required. The category
                                      of the error. Known values are: "usererror", "servererror".
                                    "code": "str",  # Optional. An identifier for
                                      the Task error. Codes are invariant and are intended to be
                                      consumed programmatically.
                                    "details": [
                                        {
                                            "name": "str",  # Optional.
                                              The name in the name-value pair.
                                            "value": "str"  # Optional.
                                              The value in the name-value pair.
                                        }
                                    ],
                                    "message": "str"  # Optional. A message
                                      describing the Task error, intended to be suitable for display in
                                      a user interface.
                                },
                                "lastRequeueTime": "2020-02-20 00:00:00",  #
                                  Optional. This property is set only if the requeueCount is nonzero.
                                "lastRetryTime": "2020-02-20 00:00:00",  # Optional.
                                  This element is present only if the Task was retried (i.e. retryCount
                                  is nonzero). If present, this is typically the same as startTime, but
                                  may be different if the Task has been restarted for reasons other
                                  than retry; for example, if the Compute Node was rebooted during a
                                  retry, then the startTime is updated but the lastRetryTime is not.
                                "requeueCount": 0,  # Required. When the user removes
                                  Compute Nodes from a Pool (by resizing/shrinking the pool) or when
                                  the Job is being disabled, the user can specify that running Tasks on
                                  the Compute Nodes be requeued for execution. This count tracks how
                                  many times the Task has been requeued for these reasons.
                                "result": "str",  # Optional. If the value is
                                  'failed', then the details of the failure can be found in the
                                  failureInfo property. Known values are: "success", "failure".
                                "retryCount": 0,  # Required. Task application
                                  failures (non-zero exit code) are retried, pre-processing errors (the
                                  Task could not be run) and file upload errors are not retried. The
                                  Batch service will retry the Task up to the limit specified by the
                                  constraints.
                                "startTime": "2020-02-20 00:00:00"  # Optional.
                                  'Running' corresponds to the running state, so if the Task specifies
                                  resource files or Packages, then the start time reflects the time at
                                  which the Task started downloading or deploying these. If the Task
                                  has been restarted or retried, this is the most recent time at which
                                  the Task started running. This property is present only for Tasks
                                  that are in the running or completed state.
                            },
                            "jobId": "str",  # Optional. The ID of the Job to which the
                              Task belongs.
                            "subtaskId": 0,  # Optional. The ID of the subtask if the
                              Task is a multi-instance Task.
                            "taskId": "str",  # Optional. The ID of the Task.
                            "taskState": "str",  # Required. The state of the Task. Known
                              values are: "active", "preparing", "running", "completed".
                            "taskUrl": "str"  # Optional. The URL of the Task.
                        }
                    ],
                    "runningTaskSlotsCount": 0,  # Optional. The total number of scheduling slots
                      used by currently running Job Tasks on the Compute Node. This includes Job
                      Manager Tasks and normal Tasks, but not Job Preparation, Job Release or Start
                      Tasks.
                    "runningTasksCount": 0,  # Optional. The total number of currently running
                      Job Tasks on the Compute Node. This includes Job Manager Tasks and normal Tasks,
                      but not Job Preparation, Job Release or Start Tasks.
                    "schedulingState": "str",  # Optional. Whether the Compute Node is available
                      for Task scheduling. Known values are: "enabled", "disabled".
                    "startTask": {
                        "commandLine": "str",  # Required. The command line does not run
                          under a shell, and therefore cannot take advantage of shell features such as
                          environment variable expansion. If you want to take advantage of such
                          features, you should invoke the shell in the command line, for example using
                          "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If the
                          command line refers to file paths, it should use a relative path (relative to
                          the Task working directory), or use the Batch provided environment variable
                          (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
                        "containerSettings": {
                            "containerRunOptions": "str",  # Optional. These additional
                              options are supplied as arguments to the "docker create" command, in
                              addition to those controlled by the Batch Service.
                            "imageName": "str",  # Required. This is the full Image
                              reference, as would be specified to "docker pull". If no tag is provided
                              as part of the Image name, the tag ":latest" is used as a default.
                            "registry": {
                                "identityReference": {
                                    "resourceId": "str"  # Optional. The ARM
                                      resource id of the user assigned identity.
                                },
                                "password": "str",  # Optional. The password to log
                                  into the registry server.
                                "registryServer": "str",  # Optional. If omitted, the
                                  default is "docker.io".
                                "username": "str"  # Optional. The user name to log
                                  into the registry server.
                            },
                            "workingDirectory": "str"  # Optional. The default is
                              'taskWorkingDirectory'. Known values are: "taskWorkingDirectory",
                              "containerImageDefault".
                        },
                        "environmentSettings": [
                            {
                                "name": "str",  # Required. The name of the
                                  environment variable.
                                "value": "str"  # Optional. The value of the
                                  environment variable.
                            }
                        ],
                        "maxTaskRetryCount": 0,  # Optional. The Batch service retries a Task
                          if its exit code is nonzero. Note that this value specifically controls the
                          number of retries. The Batch service will try the Task once, and may then
                          retry up to this limit. For example, if the maximum retry count is 3, Batch
                          tries the Task up to 4 times (one initial try and 3 retries). If the maximum
                          retry count is 0, the Batch service does not retry the Task. If the maximum
                          retry count is -1, the Batch service retries the Task without limit, however
                          this is not recommended for a start task or any task. The default value is 0
                          (no retries).
                        "resourceFiles": [
                            {
                                "autoStorageContainerName": "str",  # Optional. The
                                  autoStorageContainerName, storageContainerUrl and httpUrl properties
                                  are mutually exclusive and one of them must be specified.
                                "blobPrefix": "str",  # Optional. The property is
                                  valid only when autoStorageContainerName or storageContainerUrl is
                                  used. This prefix can be a partial filename or a subdirectory. If a
                                  prefix is not specified, all the files in the container will be
                                  downloaded.
                                "fileMode": "str",  # Optional. This property applies
                                  only to files being downloaded to Linux Compute Nodes. It will be
                                  ignored if it is specified for a resourceFile which will be
                                  downloaded to a Windows Compute Node. If this property is not
                                  specified for a Linux Compute Node, then a default value of 0770 is
                                  applied to the file.
                                "filePath": "str",  # Optional. If the httpUrl
                                  property is specified, the filePath is required and describes the
                                  path which the file will be downloaded to, including the filename.
                                  Otherwise, if the autoStorageContainerName or storageContainerUrl
                                  property is specified, filePath is optional and is the directory to
                                  download the files to. In the case where filePath is used as a
                                  directory, any directory structure already associated with the input
                                  data will be retained in full and appended to the specified filePath
                                  directory. The specified relative path cannot break out of the Task's
                                  working directory (for example by using '..').
                                "httpUrl": "str",  # Optional. The
                                  autoStorageContainerName, storageContainerUrl and httpUrl properties
                                  are mutually exclusive and one of them must be specified. If the URL
                                  points to Azure Blob Storage, it must be readable from compute nodes.
                                  There are three ways to get such a URL for a blob in Azure storage:
                                  include a Shared Access Signature (SAS) granting read permissions on
                                  the blob, use a managed identity with read permission, or set the ACL
                                  for the blob or its container to allow public access.
                                "identityReference": {
                                    "resourceId": "str"  # Optional. The ARM
                                      resource id of the user assigned identity.
                                },
                                "storageContainerUrl": "str"  # Optional. The
                                  autoStorageContainerName, storageContainerUrl and httpUrl properties
                                  are mutually exclusive and one of them must be specified. This URL
                                  must be readable and listable from compute nodes. There are three
                                  ways to get such a URL for a container in Azure storage: include a
                                  Shared Access Signature (SAS) granting read and list permissions on
                                  the container, use a managed identity with read and list permissions,
                                  or set the ACL for the container to allow public access.
                            }
                        ],
                        "userIdentity": {
                            "autoUser": {
                                "elevationLevel": "str",  # Optional. The default
                                  value is nonAdmin. Known values are: "nonadmin", "admin".
                                "scope": "str"  # Optional. The default value is
                                  pool. If the pool is running Windows a value of Task should be
                                  specified if stricter isolation between tasks is required. For
                                  example, if the task mutates the registry in a way which could impact
                                  other tasks, or if certificates have been specified on the pool which
                                  should not be accessible by normal tasks but should be accessible by
                                  StartTasks. Known values are: "task", "pool".
                            },
                            "username": "str"  # Optional. The userName and autoUser
                              properties are mutually exclusive; you must specify one but not both.
                        },
                        "waitForSuccess": bool  # Optional. If true and the StartTask fails
                          on a Node, the Batch service retries the StartTask up to its maximum retry
                          count (maxTaskRetryCount). If the Task has still not completed successfully
                          after all retries, then the Batch service marks the Node unusable, and will
                          not schedule Tasks to it. This condition can be detected via the Compute Node
                          state and failure info details. If false, the Batch service will not wait for
                          the StartTask to complete. In this case, other Tasks can start executing on
                          the Compute Node while the StartTask is still running; and even if the
                          StartTask fails, new Tasks will continue to be scheduled on the Compute Node.
                          The default is true.
                    },
                    "startTaskInfo": {
                        "containerInfo": {
                            "containerId": "str",  # Optional. The ID of the container.
                            "error": "str",  # Optional. This is the detailed error
                              string from the Docker service, if available. It is equivalent to the
                              error field returned by "docker inspect".
                            "state": "str"  # Optional. This is the state of the
                              container according to the Docker service. It is equivalent to the status
                              field returned by "docker inspect".
                        },
                        "endTime": "2020-02-20 00:00:00",  # Optional. This is the end time
                          of the most recent run of the StartTask, if that run has completed (even if
                          that run failed and a retry is pending). This element is not present if the
                          StartTask is currently running.
                        "exitCode": 0,  # Optional. This property is set only if the
                          StartTask is in the completed state. In general, the exit code for a process
                          reflects the specific convention implemented by the application developer for
                          that process. If you use the exit code value to make decisions in your code,
                          be sure that you know the exit code convention used by the application
                          process. However, if the Batch service terminates the StartTask (due to
                          timeout, or user termination via the API) you may see an operating
                          system-defined exit code.
                        "failureInfo": {
                            "category": "str",  # Required. The category of the error.
                              Known values are: "usererror", "servererror".
                            "code": "str",  # Optional. An identifier for the Task error.
                              Codes are invariant and are intended to be consumed programmatically.
                            "details": [
                                {
                                    "name": "str",  # Optional. The name in the
                                      name-value pair.
                                    "value": "str"  # Optional. The value in the
                                      name-value pair.
                                }
                            ],
                            "message": "str"  # Optional. A message describing the Task
                              error, intended to be suitable for display in a user interface.
                        },
                        "lastRetryTime": "2020-02-20 00:00:00",  # Optional. This element is
                          present only if the Task was retried (i.e. retryCount is nonzero). If
                          present, this is typically the same as startTime, but may be different if the
                          Task has been restarted for reasons other than retry; for example, if the
                          Compute Node was rebooted during a retry, then the startTime is updated but
                          the lastRetryTime is not.
                        "result": "str",  # Optional. If the value is 'failed', then the
                          details of the failure can be found in the failureInfo property. Known values
                          are: "success", "failure".
                        "retryCount": 0,  # Required. Task application failures (non-zero
                          exit code) are retried, pre-processing errors (the Task could not be run) and
                          file upload errors are not retried. The Batch service will retry the Task up
                          to the limit specified by the constraints.
                        "startTime": "2020-02-20 00:00:00",  # Required. This value is reset
                          every time the Task is restarted or retried (that is, this is the most recent
                          time at which the StartTask started running).
                        "state": "str"  # Required. The state of the StartTask on the Compute
                          Node. Known values are: "running", "completed".
                    },
                    "state": "str",  # Optional. The Spot/Low-priority Compute Node has been
                      preempted. Tasks which were running on the Compute Node when it was preempted
                      will be rescheduled when another Compute Node becomes available. Known values
                      are: "idle", "rebooting", "reimaging", "running", "unusable", "creating",
                      "starting", "waitingforstarttask", "starttaskfailed", "unknown", "leavingpool",
                      "offline", "preempted".
                    "stateTransitionTime": "2020-02-20 00:00:00",  # Optional. The time at which
                      the Compute Node entered its current state.
                    "totalTasksRun": 0,  # Optional. The total number of Job Tasks completed on
                      the Compute Node. This includes Job Manager Tasks and normal Tasks, but not Job
                      Preparation, Job Release or Start Tasks.
                    "totalTasksSucceeded": 0,  # Optional. The total number of Job Tasks which
                      completed successfully (with exitCode 0) on the Compute Node. This includes Job
                      Manager Tasks and normal Tasks, but not Job Preparation, Job Release or Start
                      Tasks.
                    "url": "str",  # Optional. The URL of the Compute Node.
                    "virtualMachineInfo": {
                        "imageReference": {
                            "exactVersion": "str",  # Optional. The specific version of
                              the platform image or marketplace image used to create the node. This
                              read-only field differs from 'version' only if the value specified for
                              'version' when the pool was created was 'latest'.
                            "offer": "str",  # Optional. For example, UbuntuServer or
                              WindowsServer.
                            "publisher": "str",  # Optional. For example, Canonical or
                              MicrosoftWindowsServer.
                            "sku": "str",  # Optional. For example, 18.04-LTS or
                              2019-Datacenter.
                            "version": "str",  # Optional. A value of 'latest' can be
                              specified to select the latest version of an Image. If omitted, the
                              default is 'latest'.
                            "virtualMachineImageId": "str"  # Optional. This property is
                              mutually exclusive with other ImageReference properties. The Shared Image
                              Gallery Image must have replicas in the same region and must be in the
                              same subscription as the Azure Batch account. If the image version is not
                              specified in the imageId, the latest version will be used. For
                              information about the firewall settings for the Batch Compute Node agent
                              to communicate with the Batch service see
                              https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
                        }
                    },
                    "vmSize": "str"  # Optional. For information about available sizes of virtual
                      machines in Pools, see Choose a VM size for Compute Nodes in an Azure Batch Pool
                      (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
                }
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        cls = kwargs.pop('cls', None)  # type: ClsType[JSON]

        
        request = build_get_request(
            pool_id=pool_id,
            node_id=node_id,
            api_version=api_version,
            select=select,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))
        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), response_headers)

        return cast(JSON, deserialized)



    @distributed_trace
    def reboot(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        node_reboot_parameter: Optional[JSON] = None,
        *,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Restarts the specified Compute Node.

        You can restart a Compute Node only if it is in an idle or running state.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the Compute Node that you want to restart.
        :type node_id: str
        :param node_reboot_parameter: The parameters for the request. Default value is None.
        :type node_reboot_parameter: JSON
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: None
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                node_reboot_parameter = {
                    "nodeRebootOption": "str"  # Optional. The default value is requeue. Known
                      values are: "requeue", "terminate", "taskcompletion", "retaineddata".
                }
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        content_type = kwargs.pop('content_type', _headers.pop('Content-Type', "application/json; odata=minimalmetadata"))  # type: Optional[str]
        cls = kwargs.pop('cls', None)  # type: ClsType[None]

        if node_reboot_parameter is not None:
            _content = node_reboot_parameter
        else:
            _content = None

        request = build_reboot_request(
            pool_id=pool_id,
            node_id=node_id,
            api_version=api_version,
            content_type=content_type,
            content=_content,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))
        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
        response_headers['DataServiceId']=self._deserialize('str', response.headers.get('DataServiceId'))


        if cls:
            return cls(pipeline_response, None, response_headers)



    @distributed_trace
    def reimage(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        node_reimage_parameter: Optional[JSON] = None,
        *,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Reinstalls the operating system on the specified Compute Node.

        You can reinstall the operating system on a Compute Node only if it is in an idle or running
        state. This API can be invoked only on Pools created with the cloud service configuration
        property.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the Compute Node that you want to restart.
        :type node_id: str
        :param node_reimage_parameter: The parameters for the request. Default value is None.
        :type node_reimage_parameter: JSON
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: None
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                node_reimage_parameter = {
                    "nodeReimageOption": "str"  # Optional. The default value is requeue. Known
                      values are: "requeue", "terminate", "taskcompletion", "retaineddata".
                }
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        content_type = kwargs.pop('content_type', _headers.pop('Content-Type', "application/json; odata=minimalmetadata"))  # type: Optional[str]
        cls = kwargs.pop('cls', None)  # type: ClsType[None]

        if node_reimage_parameter is not None:
            _content = node_reimage_parameter
        else:
            _content = None

        request = build_reimage_request(
            pool_id=pool_id,
            node_id=node_id,
            api_version=api_version,
            content_type=content_type,
            content=_content,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))
        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
        response_headers['DataServiceId']=self._deserialize('str', response.headers.get('DataServiceId'))


        if cls:
            return cls(pipeline_response, None, response_headers)



    @distributed_trace
    def disable_scheduling(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        node_disable_scheduling_parameter: Optional[JSON] = None,
        *,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Disables Task scheduling on the specified Compute Node.

        You can disable Task scheduling on a Compute Node only if its current scheduling state is
        enabled.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the Compute Node on which you want to disable Task scheduling.
        :type node_id: str
        :param node_disable_scheduling_parameter: The parameters for the request. Default value is
         None.
        :type node_disable_scheduling_parameter: JSON
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: None
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                node_disable_scheduling_parameter = {
                    "nodeDisableSchedulingOption": "str"  # Optional. The default value is
                      requeue. Known values are: "requeue", "terminate", "taskcompletion".
                }
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        content_type = kwargs.pop('content_type', _headers.pop('Content-Type', "application/json; odata=minimalmetadata"))  # type: Optional[str]
        cls = kwargs.pop('cls', None)  # type: ClsType[None]

        if node_disable_scheduling_parameter is not None:
            _content = node_disable_scheduling_parameter
        else:
            _content = None

        request = build_disable_scheduling_request(
            pool_id=pool_id,
            node_id=node_id,
            api_version=api_version,
            content_type=content_type,
            content=_content,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))
        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
        response_headers['DataServiceId']=self._deserialize('str', response.headers.get('DataServiceId'))


        if cls:
            return cls(pipeline_response, None, response_headers)



    @distributed_trace
    def enable_scheduling(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        *,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Enables Task scheduling on the specified Compute Node.

        You can enable Task scheduling on a Compute Node only if its current scheduling state is
        disabled.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the Compute Node on which you want to enable Task scheduling.
        :type node_id: str
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: None
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        cls = kwargs.pop('cls', None)  # type: ClsType[None]

        
        request = build_enable_scheduling_request(
            pool_id=pool_id,
            node_id=node_id,
            api_version=api_version,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))
        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))
        response_headers['DataServiceId']=self._deserialize('str', response.headers.get('DataServiceId'))


        if cls:
            return cls(pipeline_response, None, response_headers)



    @distributed_trace
    def get_remote_login_settings(
        self,
        pool_id: str,
        node_id: str,
        *,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> JSON:
        """Gets the settings required for remote login to a Compute Node.

        Before you can remotely login to a Compute Node using the remote login settings, you must
        create a user Account on the Compute Node. This API can be invoked only on Pools created with
        the virtual machine configuration property. For Pools created with a cloud service
        configuration, see the GetRemoteDesktop API.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the Compute Node for which to obtain the remote login settings.
        :type node_id: str
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: JSON object
        :rtype: JSON
        :raises: ~azure.core.exceptions.HttpResponseError

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response.json() == {
                    "remoteLoginIPAddress": "str",  # Required. The IP address used for remote
                      login to the Compute Node.
                    "remoteLoginPort": 0  # Required. The port used for remote login to the
                      Compute Node.
                }
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        cls = kwargs.pop('cls', None)  # type: ClsType[JSON]

        
        request = build_get_remote_login_settings_request(
            pool_id=pool_id,
            node_id=node_id,
            api_version=api_version,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))
        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), response_headers)

        return cast(JSON, deserialized)



    @distributed_trace
    def get_remote_desktop(
        self,
        pool_id: str,
        node_id: str,
        *,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> IO:
        """Gets the Remote Desktop Protocol file for the specified Compute Node.

        Before you can access a Compute Node by using the RDP file, you must create a user Account on
        the Compute Node. This API can only be invoked on Pools created with a cloud service
        configuration. For Pools created with a virtual machine configuration, see the
        GetRemoteLoginSettings API.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the Compute Node for which you want to get the Remote Desktop
         Protocol file.
        :type node_id: str
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: IO
        :rtype: IO
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        cls = kwargs.pop('cls', None)  # type: ClsType[IO]

        
        request = build_get_remote_desktop_request(
            pool_id=pool_id,
            node_id=node_id,
            api_version=api_version,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=True,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))
        response_headers['ETag']=self._deserialize('str', response.headers.get('ETag'))
        response_headers['Last-Modified']=self._deserialize('rfc-1123', response.headers.get('Last-Modified'))

        deserialized = response

        if cls:
            return cls(pipeline_response, cast(IO, deserialized), response_headers)

        return cast(IO, deserialized)



    @distributed_trace
    def upload_batch_service_logs(
        self,
        pool_id: str,
        node_id: str,
        upload_batch_service_logs_configuration: JSON,
        *,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> JSON:
        """Upload Azure Batch service log files from the specified Compute Node to Azure Blob Storage.

        This is for gathering Azure Batch service log files in an automated fashion from Compute Nodes
        if you are experiencing an error and wish to escalate to Azure support. The Azure Batch service
        log files should be shared with Azure support to aid in debugging issues with the Batch
        service.

        :param pool_id: The ID of the Pool that contains the Compute Node.
        :type pool_id: str
        :param node_id: The ID of the Compute Node from which you want to upload the Azure Batch
         service log files.
        :type node_id: str
        :param upload_batch_service_logs_configuration: The Azure Batch service log files upload
         configuration.
        :type upload_batch_service_logs_configuration: JSON
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: JSON object
        :rtype: JSON
        :raises: ~azure.core.exceptions.HttpResponseError

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                upload_batch_service_logs_configuration = {
                    "containerUrl": "str",  # Required. If a user assigned managed identity is
                      not being used, the URL must include a Shared Access Signature (SAS) granting
                      write permissions to the container. The SAS duration must allow enough time for
                      the upload to finish. The start time for SAS is optional and recommended to not
                      be specified.
                    "endTime": "2020-02-20 00:00:00",  # Optional. Any log file containing a log
                      message in the time range will be uploaded. This means that the operation might
                      retrieve more logs than have been requested since the entire log file is always
                      uploaded, but the operation should not retrieve fewer logs than have been
                      requested. If omitted, the default is to upload all logs available after the
                      startTime.
                    "identityReference": {
                        "resourceId": "str"  # Optional. The ARM resource id of the user
                          assigned identity.
                    },
                    "startTime": "2020-02-20 00:00:00"  # Required. Any log file containing a log
                      message in the time range will be uploaded. This means that the operation might
                      retrieve more logs than have been requested since the entire log file is always
                      uploaded, but the operation should not retrieve fewer logs than have been
                      requested.
                }

                # response body for status code(s): 200
                response.json() == {
                    "numberOfFilesUploaded": 0,  # Required. The number of log files which will
                      be uploaded.
                    "virtualDirectoryName": "str"  # Required. The virtual directory name is part
                      of the blob name for each log file uploaded, and it is built based poolId, nodeId
                      and a unique identifier.
                }
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        content_type = kwargs.pop('content_type', _headers.pop('Content-Type', "application/json; odata=minimalmetadata"))  # type: Optional[str]
        cls = kwargs.pop('cls', None)  # type: ClsType[JSON]

        _content = upload_batch_service_logs_configuration

        request = build_upload_batch_service_logs_request(
            pool_id=pool_id,
            node_id=node_id,
            api_version=api_version,
            content_type=content_type,
            content=_content,
            timeout=timeout,
            client_request_id=client_request_id,
            return_client_request_id=return_client_request_id,
            ocp_date=ocp_date,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers['client-request-id']=self._deserialize('str', response.headers.get('client-request-id'))
        response_headers['request-id']=self._deserialize('str', response.headers.get('request-id'))

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), response_headers)

        return cast(JSON, deserialized)



    @distributed_trace
    def list(
        self,
        pool_id: str,
        *,
        filter: Optional[str] = None,
        select: Optional[str] = None,
        max_results: Optional[int] = 1000,
        timeout: Optional[int] = 30,
        client_request_id: Optional[str] = None,
        return_client_request_id: Optional[bool] = False,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> Iterable[JSON]:
        """Lists the Compute Nodes in the specified Pool.

        Lists the Compute Nodes in the specified Pool.

        :param pool_id: The ID of the Pool from which you want to list Compute Nodes.
        :type pool_id: str
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
         https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-nodes-in-a-pool.
         Default value is None.
        :paramtype filter: str
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: str
        :keyword max_results: The maximum number of items to return in the response. A maximum of 1000
         Compute Nodes can be returned. Default value is 1000.
        :paramtype max_results: int
        :keyword timeout: The maximum time that the server can spend processing the request, in
         seconds. The default is 30 seconds.
        :paramtype timeout: int
        :keyword client_request_id: The caller-generated request identity, in the form of a GUID with
         no decoration such as curly braces, e.g. 9C4D50EE-2D56-4CD3-8152-34347DC9F2B0. Default value is
         None.
        :paramtype client_request_id: str
        :keyword return_client_request_id: Whether the server should return the client-request-id in
         the response. Default value is False.
        :paramtype return_client_request_id: bool
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API directly. Default
         value is None.
        :paramtype ocp_date: ~datetime.datetime
        :return: An iterator like instance of JSON object
        :rtype: ~azure.core.paging.ItemPaged[JSON]
        :raises: ~azure.core.exceptions.HttpResponseError

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response.json() == {
                    "odata.nextLink": "str",  # Optional. The URL to get the next set of results.
                    "value": [
                        {
                            "affinityId": "str",  # Optional. Note that this is just a
                              soft affinity. If the target Compute Node is busy or unavailable at the
                              time the Task is scheduled, then the Task will be scheduled elsewhere.
                            "allocationTime": "2020-02-20 00:00:00",  # Optional. This is
                              the time when the Compute Node was initially allocated and doesn't change
                              once set. It is not updated when the Compute Node is service healed or
                              preempted.
                            "certificateReferences": [
                                {
                                    "storeLocation": "str",  # Optional. The
                                      default value is currentuser. This property is applicable only
                                      for Pools configured with Windows Compute Nodes (that is, created
                                      with cloudServiceConfiguration, or with
                                      virtualMachineConfiguration using a Windows Image reference). For
                                      Linux Compute Nodes, the Certificates are stored in a directory
                                      inside the Task working directory and an environment variable
                                      AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for
                                      this location. For Certificates with visibility of 'remoteUser',
                                      a 'certs' directory is created in the user's home directory
                                      (e.g., /home/{user-name}/certs) and Certificates are placed in
                                      that directory. Known values are: "currentuser", "localmachine".
                                    "storeName": "str",  # Optional. This
                                      property is applicable only for Pools configured with Windows
                                      Compute Nodes (that is, created with cloudServiceConfiguration,
                                      or with virtualMachineConfiguration using a Windows Image
                                      reference). Common store names include: My, Root, CA, Trust,
                                      Disallowed, TrustedPeople, TrustedPublisher, AuthRoot,
                                      AddressBook, but any custom store name can also be used. The
                                      default value is My.
                                    "thumbprint": "str",  # Required. The
                                      thumbprint of the Certificate.
                                    "thumbprintAlgorithm": "str",  # Required.
                                      The algorithm with which the thumbprint is associated. This must
                                      be sha1.
                                    "visibility": [
                                        "str"  # Optional. You can specify
                                          more than one visibility in this collection. The default is
                                          all Accounts.
                                    ]
                                }
                            ],
                            "endpointConfiguration": {
                                "inboundEndpoints": [
                                    {
                                        "backendPort": 0,  # Required. The
                                          backend port number of the endpoint.
                                        "frontendPort": 0,  # Required. The
                                          public port number of the endpoint.
                                        "name": "str",  # Required. The name
                                          of the endpoint.
                                        "protocol": "str",  # Required. The
                                          protocol of the endpoint. Known values are: "tcp", "udp".
                                        "publicFQDN": "str",  # Required. The
                                          public fully qualified domain name for the Compute Node.
                                        "publicIPAddress": "str"  # Required.
                                          The public IP address of the Compute Node.
                                    }
                                ]
                            },
                            "errors": [
                                {
                                    "code": "str",  # Optional. An identifier for
                                      the Compute Node error. Codes are invariant and are intended to
                                      be consumed programmatically.
                                    "errorDetails": [
                                        {
                                            "name": "str",  # Optional.
                                              The name in the name-value pair.
                                            "value": "str"  # Optional.
                                              The value in the name-value pair.
                                        }
                                    ],
                                    "message": "str"  # Optional. A message
                                      describing the Compute Node error, intended to be suitable for
                                      display in a user interface.
                                }
                            ],
                            "id": "str",  # Optional. Every Compute Node that is added to
                              a Pool is assigned a unique ID. Whenever a Compute Node is removed from a
                              Pool, all of its local files are deleted, and the ID is reclaimed and
                              could be reused for new Compute Nodes.
                            "ipAddress": "str",  # Optional. Every Compute Node that is
                              added to a Pool is assigned a unique IP address. Whenever a Compute Node
                              is removed from a Pool, all of its local files are deleted, and the IP
                              address is reclaimed and could be reused for new Compute Nodes.
                            "isDedicated": bool,  # Optional. Whether this Compute Node
                              is a dedicated Compute Node. If false, the Compute Node is a
                              Spot/Low-priority Compute Node.
                            "lastBootTime": "2020-02-20 00:00:00",  # Optional. This
                              property may not be present if the Compute Node state is unusable.
                            "nodeAgentInfo": {
                                "lastUpdateTime": "2020-02-20 00:00:00",  # Required.
                                  This is the most recent time that the Compute Node agent was updated
                                  to a new version.
                                "version": "str"  # Required. This version number can
                                  be checked against the Compute Node agent release notes located at
                                  https://github.com/Azure/Batch/blob/master/changelogs/nodeagent/CHANGELOG.md.
                            },
                            "recentTasks": [
                                {
                                    "executionInfo": {
                                        "containerInfo": {
                                            "containerId": "str",  #
                                              Optional. The ID of the container.
                                            "error": "str",  # Optional.
                                              This is the detailed error string from the Docker
                                              service, if available. It is equivalent to the error
                                              field returned by "docker inspect".
                                            "state": "str"  # Optional.
                                              This is the state of the container according to the
                                              Docker service. It is equivalent to the status field
                                              returned by "docker inspect".
                                        },
                                        "endTime": "2020-02-20 00:00:00",  #
                                          Optional. This property is set only if the Task is in the
                                          Completed state.
                                        "exitCode": 0,  # Optional. This
                                          property is set only if the Task is in the completed state.
                                          In general, the exit code for a process reflects the specific
                                          convention implemented by the application developer for that
                                          process. If you use the exit code value to make decisions in
                                          your code, be sure that you know the exit code convention
                                          used by the application process. However, if the Batch
                                          service terminates the Task (due to timeout, or user
                                          termination via the API) you may see an operating
                                          system-defined exit code.
                                        "failureInfo": {
                                            "category": "str",  #
                                              Required. The category of the error. Known values are:
                                              "usererror", "servererror".
                                            "code": "str",  # Optional.
                                              An identifier for the Task error. Codes are invariant and
                                              are intended to be consumed programmatically.
                                            "details": [
                                                {
                                                    "name":
                                                      "str",  # Optional. The name in the name-value
                                                      pair.
                                                    "value":
                                                      "str"  # Optional. The value in the name-value
                                                      pair.
                                                }
                                            ],
                                            "message": "str"  # Optional.
                                              A message describing the Task error, intended to be
                                              suitable for display in a user interface.
                                        },
                                        "lastRequeueTime": "2020-02-20
                                          00:00:00",  # Optional. This property is set only if the
                                          requeueCount is nonzero.
                                        "lastRetryTime": "2020-02-20
                                          00:00:00",  # Optional. This element is present only if the
                                          Task was retried (i.e. retryCount is nonzero). If present,
                                          this is typically the same as startTime, but may be different
                                          if the Task has been restarted for reasons other than retry;
                                          for example, if the Compute Node was rebooted during a retry,
                                          then the startTime is updated but the lastRetryTime is not.
                                        "requeueCount": 0,  # Required. When
                                          the user removes Compute Nodes from a Pool (by
                                          resizing/shrinking the pool) or when the Job is being
                                          disabled, the user can specify that running Tasks on the
                                          Compute Nodes be requeued for execution. This count tracks
                                          how many times the Task has been requeued for these reasons.
                                        "result": "str",  # Optional. If the
                                          value is 'failed', then the details of the failure can be
                                          found in the failureInfo property. Known values are:
                                          "success", "failure".
                                        "retryCount": 0,  # Required. Task
                                          application failures (non-zero exit code) are retried,
                                          pre-processing errors (the Task could not be run) and file
                                          upload errors are not retried. The Batch service will retry
                                          the Task up to the limit specified by the constraints.
                                        "startTime": "2020-02-20 00:00:00"  #
                                          Optional. 'Running' corresponds to the running state, so if
                                          the Task specifies resource files or Packages, then the start
                                          time reflects the time at which the Task started downloading
                                          or deploying these. If the Task has been restarted or
                                          retried, this is the most recent time at which the Task
                                          started running. This property is present only for Tasks that
                                          are in the running or completed state.
                                    },
                                    "jobId": "str",  # Optional. The ID of the
                                      Job to which the Task belongs.
                                    "subtaskId": 0,  # Optional. The ID of the
                                      subtask if the Task is a multi-instance Task.
                                    "taskId": "str",  # Optional. The ID of the
                                      Task.
                                    "taskState": "str",  # Required. The state of
                                      the Task. Known values are: "active", "preparing", "running",
                                      "completed".
                                    "taskUrl": "str"  # Optional. The URL of the
                                      Task.
                                }
                            ],
                            "runningTaskSlotsCount": 0,  # Optional. The total number of
                              scheduling slots used by currently running Job Tasks on the Compute Node.
                              This includes Job Manager Tasks and normal Tasks, but not Job
                              Preparation, Job Release or Start Tasks.
                            "runningTasksCount": 0,  # Optional. The total number of
                              currently running Job Tasks on the Compute Node. This includes Job
                              Manager Tasks and normal Tasks, but not Job Preparation, Job Release or
                              Start Tasks.
                            "schedulingState": "str",  # Optional. Whether the Compute
                              Node is available for Task scheduling. Known values are: "enabled",
                              "disabled".
                            "startTask": {
                                "commandLine": "str",  # Required. The command line
                                  does not run under a shell, and therefore cannot take advantage of
                                  shell features such as environment variable expansion. If you want to
                                  take advantage of such features, you should invoke the shell in the
                                  command line, for example using "cmd /c MyCommand" in Windows or
                                  "/bin/sh -c MyCommand" in Linux. If the command line refers to file
                                  paths, it should use a relative path (relative to the Task working
                                  directory), or use the Batch provided environment variable
                                  (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
                                "containerSettings": {
                                    "containerRunOptions": "str",  # Optional.
                                      These additional options are supplied as arguments to the "docker
                                      create" command, in addition to those controlled by the Batch
                                      Service.
                                    "imageName": "str",  # Required. This is the
                                      full Image reference, as would be specified to "docker pull". If
                                      no tag is provided as part of the Image name, the tag ":latest"
                                      is used as a default.
                                    "registry": {
                                        "identityReference": {
                                            "resourceId": "str"  #
                                              Optional. The ARM resource id of the user assigned
                                              identity.
                                        },
                                        "password": "str",  # Optional. The
                                          password to log into the registry server.
                                        "registryServer": "str",  # Optional.
                                          If omitted, the default is "docker.io".
                                        "username": "str"  # Optional. The
                                          user name to log into the registry server.
                                    },
                                    "workingDirectory": "str"  # Optional. The
                                      default is 'taskWorkingDirectory'. Known values are:
                                      "taskWorkingDirectory", "containerImageDefault".
                                },
                                "environmentSettings": [
                                    {
                                        "name": "str",  # Required. The name
                                          of the environment variable.
                                        "value": "str"  # Optional. The value
                                          of the environment variable.
                                    }
                                ],
                                "maxTaskRetryCount": 0,  # Optional. The Batch
                                  service retries a Task if its exit code is nonzero. Note that this
                                  value specifically controls the number of retries. The Batch service
                                  will try the Task once, and may then retry up to this limit. For
                                  example, if the maximum retry count is 3, Batch tries the Task up to
                                  4 times (one initial try and 3 retries). If the maximum retry count
                                  is 0, the Batch service does not retry the Task. If the maximum retry
                                  count is -1, the Batch service retries the Task without limit,
                                  however this is not recommended for a start task or any task. The
                                  default value is 0 (no retries).
                                "resourceFiles": [
                                    {
                                        "autoStorageContainerName": "str",  #
                                          Optional. The autoStorageContainerName, storageContainerUrl
                                          and httpUrl properties are mutually exclusive and one of them
                                          must be specified.
                                        "blobPrefix": "str",  # Optional. The
                                          property is valid only when autoStorageContainerName or
                                          storageContainerUrl is used. This prefix can be a partial
                                          filename or a subdirectory. If a prefix is not specified, all
                                          the files in the container will be downloaded.
                                        "fileMode": "str",  # Optional. This
                                          property applies only to files being downloaded to Linux
                                          Compute Nodes. It will be ignored if it is specified for a
                                          resourceFile which will be downloaded to a Windows Compute
                                          Node. If this property is not specified for a Linux Compute
                                          Node, then a default value of 0770 is applied to the file.
                                        "filePath": "str",  # Optional. If
                                          the httpUrl property is specified, the filePath is required
                                          and describes the path which the file will be downloaded to,
                                          including the filename. Otherwise, if the
                                          autoStorageContainerName or storageContainerUrl property is
                                          specified, filePath is optional and is the directory to
                                          download the files to. In the case where filePath is used as
                                          a directory, any directory structure already associated with
                                          the input data will be retained in full and appended to the
                                          specified filePath directory. The specified relative path
                                          cannot break out of the Task's working directory (for example
                                          by using '..').
                                        "httpUrl": "str",  # Optional. The
                                          autoStorageContainerName, storageContainerUrl and httpUrl
                                          properties are mutually exclusive and one of them must be
                                          specified. If the URL points to Azure Blob Storage, it must
                                          be readable from compute nodes. There are three ways to get
                                          such a URL for a blob in Azure storage: include a Shared
                                          Access Signature (SAS) granting read permissions on the blob,
                                          use a managed identity with read permission, or set the ACL
                                          for the blob or its container to allow public access.
                                        "identityReference": {
                                            "resourceId": "str"  #
                                              Optional. The ARM resource id of the user assigned
                                              identity.
                                        },
                                        "storageContainerUrl": "str"  #
                                          Optional. The autoStorageContainerName, storageContainerUrl
                                          and httpUrl properties are mutually exclusive and one of them
                                          must be specified. This URL must be readable and listable
                                          from compute nodes. There are three ways to get such a URL
                                          for a container in Azure storage: include a Shared Access
                                          Signature (SAS) granting read and list permissions on the
                                          container, use a managed identity with read and list
                                          permissions, or set the ACL for the container to allow public
                                          access.
                                    }
                                ],
                                "userIdentity": {
                                    "autoUser": {
                                        "elevationLevel": "str",  # Optional.
                                          The default value is nonAdmin. Known values are: "nonadmin",
                                          "admin".
                                        "scope": "str"  # Optional. The
                                          default value is pool. If the pool is running Windows a value
                                          of Task should be specified if stricter isolation between
                                          tasks is required. For example, if the task mutates the
                                          registry in a way which could impact other tasks, or if
                                          certificates have been specified on the pool which should not
                                          be accessible by normal tasks but should be accessible by
                                          StartTasks. Known values are: "task", "pool".
                                    },
                                    "username": "str"  # Optional. The userName
                                      and autoUser properties are mutually exclusive; you must specify
                                      one but not both.
                                },
                                "waitForSuccess": bool  # Optional. If true and the
                                  StartTask fails on a Node, the Batch service retries the StartTask up
                                  to its maximum retry count (maxTaskRetryCount). If the Task has still
                                  not completed successfully after all retries, then the Batch service
                                  marks the Node unusable, and will not schedule Tasks to it. This
                                  condition can be detected via the Compute Node state and failure info
                                  details. If false, the Batch service will not wait for the StartTask
                                  to complete. In this case, other Tasks can start executing on the
                                  Compute Node while the StartTask is still running; and even if the
                                  StartTask fails, new Tasks will continue to be scheduled on the
                                  Compute Node. The default is true.
                            },
                            "startTaskInfo": {
                                "containerInfo": {
                                    "containerId": "str",  # Optional. The ID of
                                      the container.
                                    "error": "str",  # Optional. This is the
                                      detailed error string from the Docker service, if available. It
                                      is equivalent to the error field returned by "docker inspect".
                                    "state": "str"  # Optional. This is the state
                                      of the container according to the Docker service. It is
                                      equivalent to the status field returned by "docker inspect".
                                },
                                "endTime": "2020-02-20 00:00:00",  # Optional. This
                                  is the end time of the most recent run of the StartTask, if that run
                                  has completed (even if that run failed and a retry is pending). This
                                  element is not present if the StartTask is currently running.
                                "exitCode": 0,  # Optional. This property is set only
                                  if the StartTask is in the completed state. In general, the exit code
                                  for a process reflects the specific convention implemented by the
                                  application developer for that process. If you use the exit code
                                  value to make decisions in your code, be sure that you know the exit
                                  code convention used by the application process. However, if the
                                  Batch service terminates the StartTask (due to timeout, or user
                                  termination via the API) you may see an operating system-defined exit
                                  code.
                                "failureInfo": {
                                    "category": "str",  # Required. The category
                                      of the error. Known values are: "usererror", "servererror".
                                    "code": "str",  # Optional. An identifier for
                                      the Task error. Codes are invariant and are intended to be
                                      consumed programmatically.
                                    "details": [
                                        {
                                            "name": "str",  # Optional.
                                              The name in the name-value pair.
                                            "value": "str"  # Optional.
                                              The value in the name-value pair.
                                        }
                                    ],
                                    "message": "str"  # Optional. A message
                                      describing the Task error, intended to be suitable for display in
                                      a user interface.
                                },
                                "lastRetryTime": "2020-02-20 00:00:00",  # Optional.
                                  This element is present only if the Task was retried (i.e. retryCount
                                  is nonzero). If present, this is typically the same as startTime, but
                                  may be different if the Task has been restarted for reasons other
                                  than retry; for example, if the Compute Node was rebooted during a
                                  retry, then the startTime is updated but the lastRetryTime is not.
                                "result": "str",  # Optional. If the value is
                                  'failed', then the details of the failure can be found in the
                                  failureInfo property. Known values are: "success", "failure".
                                "retryCount": 0,  # Required. Task application
                                  failures (non-zero exit code) are retried, pre-processing errors (the
                                  Task could not be run) and file upload errors are not retried. The
                                  Batch service will retry the Task up to the limit specified by the
                                  constraints.
                                "startTime": "2020-02-20 00:00:00",  # Required. This
                                  value is reset every time the Task is restarted or retried (that is,
                                  this is the most recent time at which the StartTask started running).
                                "state": "str"  # Required. The state of the
                                  StartTask on the Compute Node. Known values are: "running",
                                  "completed".
                            },
                            "state": "str",  # Optional. The Spot/Low-priority Compute
                              Node has been preempted. Tasks which were running on the Compute Node
                              when it was preempted will be rescheduled when another Compute Node
                              becomes available. Known values are: "idle", "rebooting", "reimaging",
                              "running", "unusable", "creating", "starting", "waitingforstarttask",
                              "starttaskfailed", "unknown", "leavingpool", "offline", "preempted".
                            "stateTransitionTime": "2020-02-20 00:00:00",  # Optional.
                              The time at which the Compute Node entered its current state.
                            "totalTasksRun": 0,  # Optional. The total number of Job
                              Tasks completed on the Compute Node. This includes Job Manager Tasks and
                              normal Tasks, but not Job Preparation, Job Release or Start Tasks.
                            "totalTasksSucceeded": 0,  # Optional. The total number of
                              Job Tasks which completed successfully (with exitCode 0) on the Compute
                              Node. This includes Job Manager Tasks and normal Tasks, but not Job
                              Preparation, Job Release or Start Tasks.
                            "url": "str",  # Optional. The URL of the Compute Node.
                            "virtualMachineInfo": {
                                "imageReference": {
                                    "exactVersion": "str",  # Optional. The
                                      specific version of the platform image or marketplace image used
                                      to create the node. This read-only field differs from 'version'
                                      only if the value specified for 'version' when the pool was
                                      created was 'latest'.
                                    "offer": "str",  # Optional. For example,
                                      UbuntuServer or WindowsServer.
                                    "publisher": "str",  # Optional. For example,
                                      Canonical or MicrosoftWindowsServer.
                                    "sku": "str",  # Optional. For example,
                                      18.04-LTS or 2019-Datacenter.
                                    "version": "str",  # Optional. A value of
                                      'latest' can be specified to select the latest version of an
                                      Image. If omitted, the default is 'latest'.
                                    "virtualMachineImageId": "str"  # Optional.
                                      This property is mutually exclusive with other ImageReference
                                      properties. The Shared Image Gallery Image must have replicas in
                                      the same region and must be in the same subscription as the Azure
                                      Batch account. If the image version is not specified in the
                                      imageId, the latest version will be used. For information about
                                      the firewall settings for the Batch Compute Node agent to
                                      communicate with the Batch service see
                                      https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
                                }
                            },
                            "vmSize": "str"  # Optional. For information about available
                              sizes of virtual machines in Pools, see Choose a VM size for Compute
                              Nodes in an Azure Batch Pool
                              (https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
                        }
                    ]
                }
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2022-01-01.15.0"))  # type: str
        cls = kwargs.pop('cls', None)  # type: ClsType[JSON]

        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})
        def prepare_request(next_link=None):
            if not next_link:
                
                request = build_list_request(
                    pool_id=pool_id,
                    api_version=api_version,
                    filter=filter,
                    select=select,
                    max_results=max_results,
                    timeout=timeout,
                    client_request_id=client_request_id,
                    return_client_request_id=return_client_request_id,
                    ocp_date=ocp_date,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
                }
                request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

            else:
                
                request = build_list_request(
                    pool_id=pool_id,
                    client_request_id=client_request_id,
                    return_client_request_id=return_client_request_id,
                    ocp_date=ocp_date,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
                }
                request.url = self._client.format_url(next_link, **path_format_arguments)  # type: ignore

                path_format_arguments = {
                    "batchUrl": self._serialize.url("self._config.batch_url", self._config.batch_url, 'str', skip_quote=True),
                }
                request.method = "GET"
            return request

        def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = deserialized["value"]
            if cls:
                list_of_elem = cls(list_of_elem)
            return deserialized.get("odata.nextLink", None), iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response = self._client._pipeline.run(  # pylint: disable=protected-access
                request,
                stream=False,
                **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response


        return ItemPaged(
            get_next, extract_data
        )

